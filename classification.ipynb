{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4c61ff5-b8a6-4925-8c0f-b00d9ed62d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done  gamma\n",
      "Done  beta\n",
      "Done  alpha\n",
      "Done  delta\n",
      "Done  ba_1\n",
      "Done  omicron\n",
      "Done  ba_2\n",
      "Done  ba_5\n",
      "Done  ba_4\n",
      "Done  ba_3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.PDB.MMCIF2Dict import MMCIF2Dict\n",
    "from Bio.SeqUtils import seq1\n",
    "\n",
    "#write a function to get mutations within a sample that are present in 85% or more of samples\n",
    "#should take as input an annotation file, and a lineage to return values for.\n",
    "# if using lineages then requires to be handed a regex\n",
    "def get_representative_mutations(anno_file, lineage, cutoff = 0.85, overview_lineage = False, mutation_list_only = False):\n",
    "    anno_file[\"nt_aa_compound\"] = anno_file.REF + anno_file.POS.astype(\"str\") + anno_file.ALT + \"_\" + anno_file.residues\n",
    "    \n",
    "    if overview_lineage:\n",
    "        lineage_counts = anno_file.loc[anno_file.overview_lineage == lineage, \"sample_id\"].nunique()\n",
    "        mutation_counts = anno_file.loc[anno_file.overview_lineage == lineage].groupby(\"description\").nt_aa_compound.value_counts().rename(\"count\").reset_index()\n",
    "    else:\n",
    "        lineage_counts = anno_file.loc[anno_file.lineage == lineage, \"sample_id\"].nunique()\n",
    "        mutation_counts = anno_file.loc[anno_file.lineage == lineage].groupby(\"description\").nt_aa_compound.value_counts().rename(\"count\").reset_index()\n",
    "    \n",
    "    if mutation_list_only:\n",
    "        representative_mutations = mutation_counts.loc[(mutation_counts[\"count\"] >= (lineage_counts * cutoff)), \"nt_aa_compound\"]\n",
    "    else:\n",
    "        representative_mutations = mutation_counts.loc[(mutation_counts[\"count\"] >= (lineage_counts * cutoff))].copy()\n",
    "        representative_mutations[\"sample_count\"] = lineage_counts\n",
    "        representative_mutations[\"lineage\"] = lineage\n",
    "    return(representative_mutations)\n",
    "\n",
    "annotation_file = pd.read_csv(\"gisaid_sequences_spear/spear_annotation_summary.tsv\", sep = \"\\t\")\n",
    "\n",
    "metadata = pd.read_csv(\"lineages_subset_metadata.csv\")\n",
    "metadata[\"strain\"] = metadata[\"strain\"].str.replace(' ', '')\n",
    "metadata[\"strain\"] = metadata[\"strain\"].str.replace('[^a-zA-Z0-9\\.]', '_', regex = True)\n",
    "\n",
    "annotation_file_merged = annotation_file.merge(metadata, left_on = \"sample_id\", right_on = \"strain\", how = \"left\")\n",
    "\n",
    "lineages = annotation_file_merged.lineage.unique()\n",
    "\n",
    "lineage_mutations = {}\n",
    "for lineage in lineages:\n",
    "    lineage_muts = get_representative_mutations(annotation_file_merged, lineage)\n",
    "    lineage_mutations[lineage] = lineage_muts\n",
    "    print(\"Done \", lineage)\n",
    "pickle.dump(lineage_mutations, open(\"lineage_classifications/lineage_mutations_file.pkl\", \"wb\"))\n",
    "\n",
    "for lineage in lineage_mutations.keys():\n",
    "    if len(lineage_mutations[lineage]) > 0:\n",
    "        lineage_mutations[lineage].to_csv(f\"lineage_classifications/{lineage}_consensus_mutations.csv\")\n",
    "\n",
    "lineage_mutations_df = pd.concat(lineage_mutations.values(), ignore_index=True)\n",
    "\n",
    "lineage_mutations_df[\"aa\"] = lineage_mutations_df[\"nt_aa_compound\"].str.extract(r'.*_(.*)')\n",
    "\n",
    "\n",
    "pattern = r'([A-Z])([\\d\\.]+)([A-z-\\*]+)'\n",
    "#\n",
    "# Use str.extract() to create new columns for 'ref', 'pos', and 'alt'\n",
    "lineage_mutations_df[[\"ref\", \"pos\", \"alt\"]] = lineage_mutations_df['aa'].str.extract(pattern)\n",
    "\n",
    "lineage_mutations_df[\"pos\"] = lineage_mutations_df.pos.astype(float).astype(int)\n",
    "\n",
    "lineage_mutations_df[\"aa_2\"] = lineage_mutations_df[\"ref\"] + lineage_mutations_df[\"pos\"].astype(\"str\") + lineage_mutations_df[\"alt\"] \n",
    "\n",
    "#lineage_mutations_df = lineage_mutations_df.loc[lineage_mutations_df.lineage.isin([\"ba_1\", \"ba_2\", \"ba_3\", \"ba_4\",\"ba_5\"]) == False]\n",
    "\n",
    "\n",
    "spike_ab_list = pd.read_csv(\"spike_abs/ab_complexes_chains_updated.csv\")\n",
    "spike_ab_list[\"chain_id\"] = spike_ab_list['chain_id'].apply(list)\n",
    "spike_ab_list = spike_ab_list.explode(\"chain_id\")\n",
    "spike_ab_list[\"pdb_chain\"] = spike_ab_list[\"pdb\"].str.upper() + \"_\" + spike_ab_list[\"chain_id\"]\n",
    "\n",
    "\n",
    "# Define a function to safely retrieve values from the CIF data\n",
    "def get_cif_value(key):\n",
    "    try:\n",
    "        return data[key]\n",
    "    except KeyError:\n",
    "        return [None]  # Return None if the key doesn't exist in the CIF data\n",
    "\n",
    "    \n",
    "try:\n",
    "    all_cif = pd.read_pickle(\"spike_abs/all_cif.pkl\")\n",
    "except:\n",
    "    all_cif = pd.DataFrame()\n",
    "\n",
    "    for i, row in spike_ab_list.iterrows():\n",
    "        file = f\"spike_abs/cif/{row['pdb']}.cif.gz\"\n",
    "        with gzip.open(file, 'rt') as mmcif_file:\n",
    "            data = MMCIF2Dict(mmcif_file)\n",
    "\n",
    "            cif_data = {\n",
    "                \"align_id\": get_cif_value(\"_struct_ref_seq_dif.align_id\"),\n",
    "                \"pdb_id_code\": get_cif_value(\"_struct_ref_seq_dif.pdbx_pdb_id_code\"),\n",
    "                \"mon_id\": get_cif_value(\"_struct_ref_seq_dif.mon_id\"),\n",
    "                \"strand_id\": get_cif_value(\"_struct_ref_seq_dif.pdbx_pdb_strand_id\"),\n",
    "                \"seq_num\": get_cif_value(\"_struct_ref_seq_dif.seq_num\"),\n",
    "                \"pdb_ins_code\": get_cif_value(\"_struct_ref_seq_dif.pdbx_pdb_ins_code\"),\n",
    "                \"seq_db_name\": get_cif_value(\"_struct_ref_seq_dif.pdbx_seq_db_name\"),\n",
    "                \"seq_db_accession_code\": get_cif_value(\"_struct_ref_seq_dif.pdbx_seq_db_accession_code\"),\n",
    "                \"db_mon_id\": get_cif_value(\"_struct_ref_seq_dif.db_mon_id\"),\n",
    "                \"seq_db_seq_num\": get_cif_value(\"_struct_ref_seq_dif.pdbx_seq_db_seq_num\"),\n",
    "                \"details\": get_cif_value(\"_struct_ref_seq_dif.details\"),\n",
    "                \"auth_seq_num\": get_cif_value(\"_struct_ref_seq_dif.pdbx_auth_seq_num\"),\n",
    "                \"ordinal\": get_cif_value(\"_struct_ref_seq_dif.pdbx_ordinal\")\n",
    "            }\n",
    "\n",
    "        cif_df = pd.DataFrame(cif_data)\n",
    "        all_cif = pd.concat([all_cif, cif_df])\n",
    "\n",
    "    all_cif[\"pdb_chain\"] = all_cif[\"pdb_id_code\"] + \"_\" + all_cif[\"strand_id\"]\n",
    "    all_cif = all_cif.loc[all_cif.pdb_chain.isin(spike_ab_list.pdb_chain)]\n",
    "    all_cif.to_pickle(\"spike_abs/all_cif.pkl\")\n",
    "\n",
    "#for these purposes we do not consider indels\n",
    "all_cif_filtered = all_cif.loc[(all_cif.pdb_id_code.isna() == False) & (all_cif.details.isin([\"expression tag\", \"cloning artifact\", \"conflict\", \"linker\", \"initiating methionine\", \"amidation\", \"deletion\", \"insertion\"]) == False)].copy()\n",
    "\n",
    "all_cif_filtered[\"mon_id_single\"] = all_cif_filtered.mon_id.apply(seq1)\n",
    "all_cif_filtered.loc[all_cif_filtered.details == \"deletion\", \"mon_id_single\"] = \"del\"\n",
    "all_cif_filtered[\"db_mon_id_single\"] = all_cif_filtered.db_mon_id.apply(seq1)\n",
    "all_cif_filtered.loc[all_cif_filtered.details == \"insertion\", \"db_mon_id_single\"] = \"ins\"\n",
    "\n",
    "all_cif_filtered[\"aa_2\"] = all_cif_filtered[\"db_mon_id_single\"] + all_cif_filtered[\"seq_db_seq_num\"] + all_cif_filtered[\"mon_id_single\"]\n",
    "\n",
    "all_sarscov2_cif = all_cif_filtered.loc[(all_cif_filtered.seq_db_accession_code == \"P0DTC2\")].copy()\n",
    "\n",
    "all_sarscov2_cif_filtered = all_sarscov2_cif.loc[(all_sarscov2_cif.aa_2.isin([\"S383C\", \"D985C\", \"K955P\", \"V956P\",\"V705C\", \"T883C\", \"A846Y\", \"I844M\", \"K835M\", \"F817P\", \"A892P\", \"A899P\", \"A942P\", \"V367F\", \"R682G\", \"R682S\", \"R683G\", \"R683S\", \"R685G\", \"R685S\", \"K986P\", \"V987P\"]) == False)]\n",
    "all_sarscov2_cif_filtered = all_sarscov2_cif_filtered.loc[(all_sarscov2_cif_filtered.seq_db_seq_num.isin([\"682\", \"683\", \"684\", \"685\"]) == False)]\n",
    "all_sarscov2_cif_filtered = all_sarscov2_cif_filtered.drop(all_sarscov2_cif_filtered.loc[all_sarscov2_cif_filtered.pdb_id_code == \"7CAC\"].index)\n",
    "\n",
    "wt = spike_ab_list.loc[spike_ab_list.pdb.isin(all_sarscov2_cif_filtered.pdb_id_code) == False].pdb.unique().tolist()\n",
    "wt.append(\"7CAC\") #manually adding this pdb as it is wt but has unusual mutation profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b72fdd89-4059-49d1-ba82-fc3662eafec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wt       644\n",
       "ba_1      31\n",
       "beta      28\n",
       "delta     22\n",
       "alpha      7\n",
       "ba_2       6\n",
       "Name: classification, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_lineage_matches(mutations, lineage_file):\n",
    "    if mutations.values.tolist() == [\"N501Y\"]:\n",
    "        max_lineage = \"alpha\"\n",
    "        lineage_stats = {\"method\" : \"assigned by single mut\"}\n",
    "        return max_lineage, lineage_stats\n",
    "    elif mutations.values.tolist() == [\"D614G\"]:\n",
    "        max_lineage = \"delta\"\n",
    "        lineage_stats = {\"method\" : \"assigned by single mut\"}\n",
    "        return max_lineage, lineage_stats\n",
    "    lineage_stats = {}\n",
    "    max_perc = 0\n",
    "    max_lineage = None\n",
    "    for lineage, group in lineage_file.loc[(lineage_file.description == \"surface glycoprotein\") & (lineage_file.lineage != \"omicron\")].groupby(\"lineage\"):\n",
    "        lineage_total_muts = len(group)\n",
    "        lineage_match_muts = group.loc[group.aa_2.isin(mutations)]\n",
    "        lineage_match_count = len(lineage_match_muts)\n",
    "        perc_matches = lineage_match_count/lineage_total_muts\n",
    "        additional_mutations = len(mutations) - lineage_match_count\n",
    "        lineage_stats[lineage] = {\"lineage_match_count\" : lineage_match_count, \"percentage_matches\" : perc_matches, \"num_additional_mutations\" : additional_mutations, \"method\": \"assigned by perc\"}\n",
    "        if perc_matches > max_perc:\n",
    "            max_perc = perc_matches\n",
    "            max_lineage = lineage\n",
    "    if (max_lineage == None):\n",
    "        max_lineage = \"to investigate\"\n",
    "    return max_lineage, lineage_stats\n",
    "\n",
    "results = {}\n",
    "for i, group in all_sarscov2_cif_filtered.groupby([\"pdb_id_code\", \"strand_id\"]):\n",
    "    group = group.reset_index()\n",
    "    structure = f\"{group.pdb_id_code.values[0]}_{group.strand_id.values[0]}\"\n",
    "    result = count_lineage_matches(group.aa_2, lineage_mutations_df)\n",
    "    results[structure] = [result[0], result[1]]\n",
    "\n",
    "classification_results = pd.DataFrame(results).T.reset_index()\n",
    "classification_results = classification_results.rename(columns = {\"index\": \"pdb_chain_id\", 0: \"classification\", 1 : \"classification_stats\"})\n",
    "\n",
    "wt_spike = spike_ab_list.loc[spike_ab_list.pdb.isin(wt), [\"pdb_chain\"]].copy().rename(columns = {\"pdb_chain\": \"pdb_chain_id\"})\n",
    "\n",
    "wt_spike[\"classification\"] = \"wt\"\n",
    "wt_spike[\"classification_stats\"] = \"no mutations after filtering\"\n",
    "\n",
    "all_classification_results = pd.concat([wt_spike, classification_results])\n",
    "all_classification_results[\"pdb\"] = all_classification_results[\"pdb_chain_id\"].str[:4]\n",
    "\n",
    "all_classification_results[\"pdb\"].nunique()\n",
    "\n",
    "all_classification_results.drop_duplicates(\"pdb\").classification.value_counts(dropna = False)\n",
    "\n",
    "all_classification_results = all_classification_results.drop_duplicates(\"pdb\")\n",
    "all_classification_results.to_pickle(\"all_classification_results.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:longitudinal_analysis]",
   "language": "python",
   "name": "conda-env-longitudinal_analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
